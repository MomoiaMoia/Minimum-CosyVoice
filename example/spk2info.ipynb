{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **spk2info.pt 微调**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from hyperpyyaml import load_hyperpyyaml  # type: ignore\n",
    "\n",
    "import torch\n",
    "import librosa  # type: ignore\n",
    "\n",
    "from torchaudio import transforms  # type: ignore\n",
    "from cosyvoice.cli.frontend import CosyVoiceFrontEnd  # type: ignore\n",
    "from cosyvoice.utils.file_utils import load_wav  # type: ignore\n",
    "from config_tts import TTSConfig\n",
    "\n",
    "max_val = 0.8\n",
    "prompt_sr, target_sr = 16000, 22050\n",
    "\n",
    "def postprocess(speech, top_db=60, hop_length=220, win_length=440):\n",
    "    speech, _ = librosa.effects.trim(\n",
    "        speech, top_db=top_db, frame_length=win_length, hop_length=hop_length\n",
    "    )\n",
    "    if speech.abs().max() > max_val:\n",
    "        speech = speech / speech.abs().max() * max_val\n",
    "    speech = torch.concat([speech, torch.zeros(1, int(target_sr * 0.2))], dim=1)\n",
    "    return speech\n",
    "\n",
    "\n",
    "# 加载前端\n",
    "TTS_DIR = os.path.expanduser(TTSConfig.MODELPATH)\n",
    "MODEL_DIR = os.path.join(TTS_DIR, TTSConfig.MODEL)\n",
    "with open(rf\"{MODEL_DIR}/cosyvoice.yaml\", \"r\") as f:\n",
    "    configs = load_hyperpyyaml(f)\n",
    "\n",
    "cosyvoice = CosyVoiceFrontEnd(\n",
    "    configs[\"get_tokenizer\"],\n",
    "    configs[\"feat_extractor\"],\n",
    "    \"{}/campplus.onnx\".format(MODEL_DIR),\n",
    "    \"{}/speech_tokenizer_v1.onnx\".format(MODEL_DIR),\n",
    "    \"{}/spk2info.pt\".format(MODEL_DIR),\n",
    "    configs[\"allowed_special\"],\n",
    ")\n",
    "\n",
    "# 提取，写入特征\n",
    "def add_spk(cosyvoice: CosyVoiceFrontEnd, wav_path: str, speaker_name: str):\n",
    "    prompt_speech_16k = postprocess(load_wav(wav_path, prompt_sr))\n",
    "    embedding = cosyvoice._extract_spk_embedding(prompt_speech_16k)\n",
    "\n",
    "    cosyvoice.spk2info[speaker_name] = {\n",
    "        \"embedding\": embedding,\n",
    "    }\n",
    "\n",
    "wav_paths = [r\"D:\\Segment_b\\Code\\code\\swarmclone.cosyvoice\\example\\output\\1.2n_-0.2x.mp3\"]\n",
    "speaker_names = [\"知络_1.2\"]\n",
    "\n",
    "for wave_path, speaker_name in zip(wav_paths, speaker_names):\n",
    "    print(f\" * 正在添加 {speaker_name} 到 spk2info.pt\")\n",
    "    add_spk(cosyvoice, wave_path, speaker_name)\n",
    "\n",
    "torch.save(cosyvoice.spk2info, r\"C:\\Users\\11327\\.swarmclone\\tts_cosy_voice\\CosyVoice-300M-Instruct\\spk2info.pt\")\n",
    "spk2info = torch.load(r\"C:\\Users\\11327\\.swarmclone\\tts_cosy_voice\\CosyVoice-300M-Instruct\\spk2info.pt\")\n",
    "\n",
    "for spk in speaker_names:\n",
    "    if spk in spk2info.keys():\n",
    "        print(f\" * 添加 {spk} 成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **speaker interploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "spk2info = torch.load(\n",
    "    r\"D:\\Segment_b\\Code\\code\\swarmclone.cosyvoice\\example\\spk2info_finetune\\spk2info.pt\"\n",
    ")\n",
    "\n",
    "mix_spk_1 = spk2info[\"neuro\"]\n",
    "mix_spk_2 = spk2info[\"xiaoling\"]\n",
    "\n",
    "mix_spk_1 = spk2info[\"zhiluo_1.1neuro_-0.1xiaoling\"]\n",
    "mix_spk_2 = spk2info[\"中文女\"]\n",
    "\n",
    "for ratio in [0.9]:\n",
    "    spk2info[f\"zhiluo_{ratio:.1f}mixer_0.9_{(1-ratio):.1f}nv\"] = {}\n",
    "    for (k, v_1), (_, v_2) in zip(mix_spk_1.items(), mix_spk_2.items()):\n",
    "        spk2info[f\"zhiluo_{ratio:.1f}mixer_0.9_{(1-ratio):.1f}nv\"][k] = ratio * v_1 + (1 - ratio) * v_2\n",
    "    \n",
    "for spk in spk2info.keys():\n",
    "    print(spk)\n",
    "    for k, v in spk2info[spk].items():\n",
    "        print(k, v.shape)\n",
    "        \n",
    "torch.save(spk2info, r\"C:\\Users\\11327\\.swarmclone\\tts_cosy_voice\\CosyVoice-300M-Instruct\\spk2info.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rename Keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "spk2info = torch.load(\n",
    "    r\"D:\\Segment_b\\Code\\code\\swarmclone.cosyvoice\\example\\spk2info_finetune\\spk2info.pt\"\n",
    ")\n",
    "for k in ['中文女', '中文男', '日语男', '粤语女', '英文女', '英文男', '韩语女', 'neuro', 'xiaoling']:\n",
    "    spk2info.pop(k)\n",
    "\n",
    "for k in list(spk2info.keys()):\n",
    "    if k not in (\"zhiluo_0.7neuro_0.3xiaoling\", \"zhiluo_1.2neuro_-0.2xiaoling\"):\n",
    "        spk2info.pop(k)\n",
    "    else:\n",
    "        spk2info[\"知络\" + k[6:10]] = spk2info.pop(k)\n",
    "        \n",
    "spk2info.keys()\n",
    "\n",
    "torch.save(spk2info, r\"D:\\Segment_b\\Code\\code\\swarmclone.cosyvoice\\example\\spk2info_finetune\\mixer.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.load(r\"D:\\Segment_b\\Code\\code\\swarmclone.cosyvoice\\example\\spk2info_finetune\\mixer.pt\").keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
